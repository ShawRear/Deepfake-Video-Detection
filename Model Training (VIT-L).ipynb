{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms, models\nfrom tqdm import tqdm\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.amp import GradScaler, autocast  # For mixed precision training\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\n# Set device and configure workers\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nnum_workers = 0 if torch.cuda.is_available() else 4  # Use 4 workers if on CPU\n\n# Batch size adjustment for Kaggle GPU P100 (smaller batch size to avoid OOM)\nbatch_size = 32 if torch.cuda.is_available() else 4  # Reduce for GPU, adjust for CPU\n\n# Resize image size and convert to float16 for reduced memory footprint\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),  # Horizontal flip for augmentation\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # Data augmentation\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Pretrained ImageNet stats\n])\n\n# Load dataset (train and validation directories)\ntrain_data = datasets.ImageFolder(root='/input/train', transform=transform)\nval_data = datasets.ImageFolder(root='/input/session_1/val', transform=transform)\n\n# Convert images to float16\ndef convert_to_float16(image):\n    return image.half()  # Convert tensor to half-precision (float16)\n\n# Data Loaders with Image to float16 conversion\nclass MyDataLoader(DataLoader):\n    def __init__(self, dataset, batch_size, shuffle, num_workers):\n        super().__init__(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n    \n    def collate_fn(self, batch):\n        images, labels = zip(*batch)\n        images = torch.stack(images)\n        images = convert_to_float16(images)  # Convert the batch of images to float16\n        labels = torch.tensor(labels, dtype=torch.long)\n        return images, labels\n\ntrain_loader = MyDataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\nval_loader = MyDataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n\n# Model with dropout\nclass ViTWithDropout(nn.Module):\n    def __init__(self):\n        super(ViTWithDropout, self).__init__()\n        self.model = models.vit_l_16(weights=\"IMAGENET1K_V1\")\n        self.model.heads.head = nn.Sequential(\n            nn.Dropout(0.5),  # Dropout before the final layer\n            nn.Linear(self.model.heads.head.in_features, 2)  # 2 output classes\n        )\n\n    def forward(self, x):\n        return self.model(x)\n\nmodel = ViTWithDropout().to(device)\n\n# Loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\nscheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)\nscaler = GradScaler() # Mixed Precision Setup\n\n# Paths for model saving and loading\nprevious_model_path = \"input/deepfake_model_session1.pth\"  # Path to the previously saved model\ncurrent_model_name = \"vitL_deepfake_model_session2.pth\"  # New name for the current session's model\ncurrent_model_path = os.path.join(\"/working/directory\", current_model_name)  # Save new model in the working directory\n\n# Load previous checkpoint if exists\nif os.path.exists(previous_model_path):\n    print(f\"Loading model from {previous_model_path}...\")\n    checkpoint = torch.load(previous_model_path, weights_only=True)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    start_epoch = checkpoint['epoch']\n    best_val_loss = checkpoint['val_loss']\n    print(f\"Resumed from epoch {start_epoch + 1}\")\nelse:\n    start_epoch = 0\n    best_val_loss = float(\"inf\")\n\n# Training settings\ntotal_epochs = 30\naccumulation_steps = 2  # Accumulate gradients over 4 mini-batches\npatience_counter = 0\n\n# Track metrics\ntrain_losses = []\nval_losses = []\ntrain_metrics = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\nval_metrics = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n\n# Early stopping\nearly_stopping_patience = 3\nbest_val_loss = float(\"inf\")\npatience_counter = 0\n\n\n# Training loop\nfor epoch in range(start_epoch, total_epochs):\n    print(f\"Epoch {epoch + 1}/{total_epochs}\")\n    train_loss = 0.0\n    val_loss = 0.0\n    all_train_preds = []\n    all_train_labels = []\n    all_val_preds = []\n    all_val_labels = []\n\n    # Training phase\n    model.train()\n    optimizer.zero_grad()  # Reset gradients before each training epoch\n    train_progress = tqdm(train_loader, desc=\"Training\", leave=False)\n    \n    for step, (images, labels) in enumerate(train_progress):\n        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n\n        # Mixed precision: forward pass and loss computation\n        with autocast(device_type='cuda'):\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n        # Scale the loss and backpropagate\n        scaler.scale(loss).backward()\n\n        # Accumulate gradients\n        if (step + 1) % accumulation_steps == 0 or (step + 1) == len(train_loader):\n            scaler.step(optimizer)  # Update model parameters\n            scaler.update()  # Update the scaler\n            optimizer.zero_grad()  # Reset gradients after the update\n\n        train_loss += loss.item() * images.size(0)\n        preds = torch.argmax(outputs, dim=1)\n        all_train_preds.extend(preds.cpu().numpy())\n        all_train_labels.extend(labels.cpu().numpy())\n\n        train_progress.set_postfix({\"Loss\": loss.item()})\n\n    train_loss /= len(train_loader.dataset)\n    train_losses.append(train_loss)\n\n    # Calculate training metrics\n    train_accuracy = accuracy_score(all_train_labels, all_train_preds)\n    train_precision = precision_score(all_train_labels, all_train_preds)\n    train_recall = recall_score(all_train_labels, all_train_preds)\n    train_f1 = f1_score(all_train_labels, all_train_preds)\n    train_metrics['accuracy'].append(train_accuracy)\n    train_metrics['precision'].append(train_precision)\n    train_metrics['recall'].append(train_recall)\n    train_metrics['f1'].append(train_f1)\n\n    # Validation phase\n    model.eval()\n    with torch.no_grad():\n        val_progress = tqdm(val_loader, desc=\"Validating\", leave=False)\n        for images, labels in val_progress:\n            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n\n            # Mixed precision: forward pass and loss computation\n            with autocast(device_type='cuda'):\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n\n            val_loss += loss.item() * images.size(0)\n\n            preds = torch.argmax(outputs, dim=1)\n            all_val_preds.extend(preds.cpu().numpy())\n            all_val_labels.extend(labels.cpu().numpy())\n            val_progress.set_postfix({\"Loss\": loss.item()})\n\n    val_loss /= len(val_loader.dataset)\n    val_losses.append(val_loss)\n    scheduler.step(val_loss)\n\n    # Calculate validation metrics\n    val_accuracy = accuracy_score(all_val_labels, all_val_preds)\n    val_precision = precision_score(all_val_labels, all_val_preds)\n    val_recall = recall_score(all_val_labels, all_val_preds)\n    val_f1 = f1_score(all_val_labels, all_val_preds)\n    val_metrics['accuracy'].append(val_accuracy)\n    val_metrics['precision'].append(val_precision)\n    val_metrics['recall'].append(val_recall)\n    val_metrics['f1'].append(val_f1)\n\n   # Early stopping check\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        patience_counter = 0\n        # Save the updated model with the current session's name\n        torch.save({\n            'epoch': epoch + 1,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'train_loss': train_loss,\n            'val_loss': val_loss\n        }, current_model_path)\n        print(f\"Model saved as {current_model_name}\")\n    else:\n        patience_counter += 1\n        if patience_counter >= early_stopping_patience:\n            print(\"Early stopping triggered.\")\n            break\n            \n    # Print epoch summary with metrics\n    print(f\"Epoch [{epoch+1}/{total_epochs}], Train Loss: {train_loss:.4f}, \"\n          f\"Train Accuracy: {train_accuracy:.4f}, Train F1: {train_f1:.4f}, \"\n          f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, Val F1: {val_f1:.4f}\")\n\n# Plot Loss\nplt.figure(figsize=(10, 5))\nplt.plot(train_losses, label=\"Train Loss\")\nplt.plot(val_losses, label=\"Val Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()\n\n# Plot metrics\nmetrics = ['accuracy', 'precision', 'recall', 'f1']\nfor metric in metrics:\n    plt.figure(figsize=(10, 5))\n    plt.plot(range(1, len(train_metrics[metric]) + 1), train_metrics[metric], label=f\"Train {metric}\")\n    plt.plot(range(1, len(val_metrics[metric]) + 1), val_metrics[metric], label=f\"Val {metric}\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(f\"{metric.capitalize()}\")\n    plt.legend()\n    plt.show()\n    \n# Plot Loss and Metrics\nplt.figure(figsize=(15, 8))\nepochs_range = range(1, len(train_losses) + 1)\n\n# Loss Plot\nplt.subplot(2, 1, 1)\nplt.plot(epochs_range, train_losses, label=\"Train Loss\", marker='o')\nplt.plot(epochs_range, val_losses, label=\"Validation Loss\", marker='o')\nplt.title(\"Loss vs Epochs\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.grid(True)\n\n# Metrics Plot\nplt.subplot(2, 1, 2)\nfor metric in ['accuracy', 'precision', 'recall', 'f1']:\n    plt.plot(epochs_range, train_metrics[metric], label=f\"Train {metric.capitalize()}\", linestyle='--')\n    plt.plot(epochs_range, val_metrics[metric], label=f\"Val {metric.capitalize()}\", linestyle='-')\nplt.title(\"Metrics vs Epochs\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Metrics\")\nplt.legend()\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n\n# Confusion Matrix for Validation Set\nmodel.eval()  # Ensure model is in evaluation mode\nall_val_preds = []\nall_val_labels = []\n\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n        with autocast(device_type='cuda'):\n            outputs = model(images)\n        preds = torch.argmax(outputs, dim=1)\n        all_val_preds.extend(preds.cpu().numpy())\n        all_val_labels.extend(labels.cpu().numpy())\n\n# Compute confusion matrix\ncm = confusion_matrix(all_val_labels, all_val_preds)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=train_data.classes)\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\ndisp.plot(cmap=\"Blues\", values_format='d', ax=plt.gca())\nplt.title(\"Confusion Matrix - Validation Set\")\nplt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}