{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models, transforms\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Define the device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Define the ViT model with dropout\nclass ViTWithDropout(nn.Module):\n    def __init__(self):\n        super(ViTWithDropout, self).__init__()\n        self.model = models.vit_l_16(weights=\"IMAGENET1K_V1\")\n        self.model.heads.head = nn.Sequential(\n            nn.Dropout(0.5),  # Dropout before the final layer\n            nn.Linear(self.model.heads.head.in_features, 2)  # 2 output classes\n        )\n\n    def forward(self, x):\n        return self.model(x)\n\n# Load the trained model\nmodel = ViTWithDropout().to(device)\ncheckpoint_path = \"/input/deepfake_model_session5.pth\"  # Path to your best model checkpoint\ncheckpoint = torch.load(checkpoint_path, map_location=device, weights_only=True)\nmodel.load_state_dict(checkpoint[\"model_state_dict\"])\nmodel.eval()  # Set model to evaluation mode\n\n# Define test dataset transformations (without augmentation)\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Load test dataset\nfrom torchvision.datasets import ImageFolder  # Update based on your dataset loading method\ntest_dataset = ImageFolder(root=\"/input/test\", transform=test_transform)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# Evaluate the model on the test set and calculate confusion matrix\ny_true = []\ny_pred = []\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, preds = torch.max(outputs, 1)\n        y_true.extend(labels.cpu().numpy())\n        y_pred.extend(preds.cpu().numpy())\n\n# Confusion Matrix and Classification Report\nconf_matrix = confusion_matrix(y_true, y_pred)\nclass_names = test_dataset.classes  # Assuming class names are available in dataset\n\nprint(\"Classification Report:\")\nprint(classification_report(y_true, y_pred, target_names=class_names))\n\n# Plot confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}